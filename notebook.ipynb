{"cells":[{"source":"# Practical Exam: Customer Purchase Prediction\n\nRetailTech Solutions is a fast-growing international e-commerce platform operating in over 20 countries across Europe, North America, and Asia. They specialize in fashion, electronics, and home goods, with a unique business model that combines traditional retail with a marketplace for independent sellers.\n\nThe company has seen rapid growth. A key part of their success has been their data-driven approach to personalization. However, as they plan their expansion into new markets, they need to improve their ability to predict customer behavior.\n\nTheir marketing team wants to predict which customers are most likely to make a purchase based on their browsing behavior.\n\nAs an AI Engineer, you will help build this prediction system. Your work will directly impact RetailTech's growth strategy and their goal of increasing revenue.\n\n\n## Data Description\n\n| Column Name | Criteria |\n|------------|----------|\n| customer_id | Integer. Unique identifier for each customer. No missing values. |\n| time_spent | Float. Minutes spent on website per session. Missing values should be replaced with median. |\n| pages_viewed | Integer. Number of pages viewed in session. Missing values should be replaced with mean. |\n| basket_value | Float. Value of items in basket. Missing values should be replaced with 0. |\n| device_type | String. One of: Mobile, Desktop, Tablet. Missing values should be replaced with \"Unknown\". |\n| customer_type | String. One of: New, Returning. Missing values should be replaced with \"New\". |\n| purchase | Binary. Whether customer made a purchase (1) or not (0). Target variable. |","metadata":{},"cell_type":"markdown","id":"8d0bcede-0826-475c-8678-72835c042b37"},{"source":"# Task 1\n\nThe marketing team has collected customer session data in `raw_customer_data.csv`, but it contains missing values and inconsistencies that need to be addressed.\nCreate a cleaned version of the dataframe:\n\n- Start with the data in the file `raw_customer_data.csv`\n- Your output should be a DataFrame named `clean_data`\n- All column names and values should match the table below.\n</br>\n\n| Column Name | Criteria |\n|------------|----------|\n| customer_id | Integer. Unique identifier for each customer. No missing values. |\n| time_spent | Float. Minutes spent on website per session. Missing values should be replaced with median. |\n| pages_viewed | Integer. Number of pages viewed in session. Missing values should be replaced with mean. |\n| basket_value | Float. Value of items in basket. Missing values should be replaced with 0. |\n| device_type | String. One of: Mobile, Desktop, Tablet. Missing values should be replaced with \"Unknown\". |\n| customer_type | String. One of: New, Returning. Missing values should be replaced with \"New\". |\n| purchase | Binary. Whether customer made a purchase (1) or not (0). Target variable. |","metadata":{},"id":"c0d5a3bb-bbae-4d39-a6c6-daa46c470347","cell_type":"markdown"},{"source":"# Task 1\n\nimport pandas as pd\n\n# Load data\nraw_data = pd.read_csv('raw_customer_data.csv')\n\n# Clean the data\nclean_data = raw_data.copy()\n\n# Ensure the customer_id is int and it has no missing values\nclean_data['customer_id'] = clean_data['customer_id'].astype(int)\n\n# Replace missing time_spent with median time spent\nmedian_time_spent = clean_data['time_spent'].median()\nclean_data['time_spent'] = clean_data['time_spent'].fillna(median_time_spent).astype(float)\n\n# Replace missing pages_viewed with mean\nmean_pages_viewed = clean_data['pages_viewed'].mean()\nclean_data['pages_viewed'] = clean_data['pages_viewed'].fillna(mean_pages_viewed).astype(int)\n\n# Replace missing basket_value with 0\nclean_data['basket_value'] = clean_data['basket_value'].fillna(0).astype(float)\n\n# Replace missing device_type with \"Unknown\"\nclean_data['device_type'] = clean_data['device_type'].fillna(\"Unknown\")\n\n# Replace missing customer_type with \"New\"\nclean_data['customer_type'] = clean_data['customer_type'].fillna(\"New\")\n\n# Ensure purchase is binary (1 or 0)\nclean_data['purchase'] = clean_data['purchase'].astype(int)\n\n# Display the cleaned data\nclean_data.head()\n","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1740095774616,"lastExecutedByKernel":"32139c46-8d69-43b5-b167-7bde76e910ec","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Task 1\n\nimport pandas as pd\n\n# Load data\nraw_data = pd.read_csv('raw_customer_data.csv')\n\n# Clean the data\nclean_data = raw_data.copy()\n\n# Ensure the customer_id is int and it has no missing values\nclean_data['customer_id'] = clean_data['customer_id'].astype(int)\n\n# Replace missing time_spent with median time spent\nmedian_time_spent = clean_data['time_spent'].median()\nclean_data['time_spent'] = clean_data['time_spent'].fillna(median_time_spent).astype(float)\n\n# Replace missing pages_viewed with mean\nmean_pages_viewed = clean_data['pages_viewed'].mean()\nclean_data['pages_viewed'] = clean_data['pages_viewed'].fillna(mean_pages_viewed).astype(int)\n\n# Replace missing basket_value with 0\nclean_data['basket_value'] = clean_data['basket_value'].fillna(0).astype(float)\n\n# Replace missing device_type with \"Unknown\"\nclean_data['device_type'] = clean_data['device_type'].fillna(\"Unknown\")\n\n# Replace missing customer_type with \"New\"\nclean_data['customer_type'] = clean_data['customer_type'].fillna(\"New\")\n\n# Ensure purchase is binary (1 or 0)\nclean_data['purchase'] = clean_data['purchase'].astype(int)\n\n# Display the cleaned data\nclean_data.head()\n","outputsMetadata":{"0":{"height":261,"type":"dataFrame","tableState":{"quickFilterText":"","customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"4699f129-0d86-46e0-9f87-69de20dc0a11","nodeType":"const"}}}}},"id":"5ce18b54-29af-4beb-bc8c-79c4e21bcd52","cell_type":"code","execution_count":18,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"customer_id","type":"integer"},{"name":"time_spent","type":"number"},{"name":"pages_viewed","type":"integer"},{"name":"basket_value","type":"number"},{"name":"device_type","type":"string"},{"name":"customer_type","type":"string"},{"name":"purchase","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"customer_id":[1,2,3,4,5],"time_spent":[23.097867012,57.0921440782,44.1876425669,36.3208505676,10.2050997861],"pages_viewed":[7,3,14,10,16],"basket_value":[50.5746474517,56.891022415,8.3482957768,43.4814890919,0],"device_type":["Mobile","Mobile","Mobile","Mobile","Mobile"],"customer_type":["Returning","Returning","Returning","New","Returning"],"purchase":[0,1,0,1,1]}},"total_rows":5,"truncation_type":null},"text/plain":"   customer_id  time_spent  pages_viewed  ...  device_type customer_type purchase\n0            1   23.097867             7  ...       Mobile     Returning        0\n1            2   57.092144             3  ...       Mobile     Returning        1\n2            3   44.187643            14  ...       Mobile     Returning        0\n3            4   36.320851            10  ...       Mobile           New        1\n4            5   10.205100            16  ...       Mobile     Returning        1\n\n[5 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>time_spent</th>\n      <th>pages_viewed</th>\n      <th>basket_value</th>\n      <th>device_type</th>\n      <th>customer_type</th>\n      <th>purchase</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>23.097867</td>\n      <td>7</td>\n      <td>50.574647</td>\n      <td>Mobile</td>\n      <td>Returning</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>57.092144</td>\n      <td>3</td>\n      <td>56.891022</td>\n      <td>Mobile</td>\n      <td>Returning</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>44.187643</td>\n      <td>14</td>\n      <td>8.348296</td>\n      <td>Mobile</td>\n      <td>Returning</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>36.320851</td>\n      <td>10</td>\n      <td>43.481489</td>\n      <td>Mobile</td>\n      <td>New</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>10.205100</td>\n      <td>16</td>\n      <td>0.000000</td>\n      <td>Mobile</td>\n      <td>Returning</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":18}]},{"source":"# Task 2\nThe pre-cleaned dataset `model_data.csv` needs to be prepared for our neural network.\nCreate the model features:\n\n- Start with the data in the file `model_data.csv`\n- Scale numerical features (`time_spent`, `pages_viewed`, `basket_value`) to 0-1 range\n- Apply one-hot encoding to the categorical features (`device_type`, `customer_type`)\n    - The column names should have the following format: variable_name_category_name (e.g., `device_type_Desktop`)\n- Your output should be a DataFrame named `model_feature_set`, with all column names from `model_data.csv` except for the columns where one-hot encoding was applied.\n","metadata":{},"id":"026b3c30-d3b0-4762-ae10-0f2880873bdc","cell_type":"markdown"},{"source":"# Task 2\n\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n\n# Load Pre-cleaned dataset\nmodel_data = pd.read_csv('model_data.csv')\n\n# Scale numerical features to 0-1 range\nscaler = MinMaxScaler()\nnumerical_features = ['time_spent', 'pages_viewed', 'basket_value']\nmodel_data[numerical_features] = scaler.fit_transform(model_data[numerical_features])\n\n# Apply one-hot encoding to categorical features\ncategorical_features = ['device_type', 'customer_type']\nencoder = OneHotEncoder(sparse=False, drop='first')  # I drop first to avoid multicollinearity\nencoded_features = encoder.fit_transform(model_data[categorical_features])\n\n# Create DataFrame for encoded features\nencoded_columns = encoder.get_feature_names_out(categorical_features)\nencoded_df = pd.DataFrame(encoded_features, columns=encoded_columns)\n\n# Combine scaled numerical features and encoded categorical features\nmodel_feature_set = pd.concat([model_data.drop(columns=categorical_features), encoded_df], axis=1)\n\n# Display the prepared feature set\nmodel_feature_set.head()","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1740095774671,"lastExecutedByKernel":"32139c46-8d69-43b5-b167-7bde76e910ec","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Task 2\n\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n\n# Load Pre-cleaned dataset\nmodel_data = pd.read_csv('model_data.csv')\n\n# Scale numerical features to 0-1 range\nscaler = MinMaxScaler()\nnumerical_features = ['time_spent', 'pages_viewed', 'basket_value']\nmodel_data[numerical_features] = scaler.fit_transform(model_data[numerical_features])\n\n# Apply one-hot encoding to categorical features\ncategorical_features = ['device_type', 'customer_type']\nencoder = OneHotEncoder(sparse=False, drop='first')  # I drop first to avoid multicollinearity\nencoded_features = encoder.fit_transform(model_data[categorical_features])\n\n# Create DataFrame for encoded features\nencoded_columns = encoder.get_feature_names_out(categorical_features)\nencoded_df = pd.DataFrame(encoded_features, columns=encoded_columns)\n\n# Combine scaled numerical features and encoded categorical features\nmodel_feature_set = pd.concat([model_data.drop(columns=categorical_features), encoded_df], axis=1)\n\n# Display the prepared feature set\nmodel_feature_set.head()","outputsMetadata":{"0":{"height":261,"type":"dataFrame","tableState":{"quickFilterText":""}}}},"id":"6d47e440-c4ab-45cf-af40-53181764bac4","cell_type":"code","execution_count":19,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"customer_id","type":"integer"},{"name":"time_spent","type":"number"},{"name":"pages_viewed","type":"number"},{"name":"basket_value","type":"number"},{"name":"purchase","type":"integer"},{"name":"device_type_Mobile","type":"number"},{"name":"device_type_Tablet","type":"number"},{"name":"device_type_Unknown","type":"number"},{"name":"customer_type_Returning","type":"number"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"customer_id":[501,502,503,504,505],"time_spent":[0.6641673486,0.4836806636,0.2313587256,0.792944242,0.6492102097],"pages_viewed":[0.5,0.2222222222,0.1111111111,0.2777777778,0.1666666667],"basket_value":[0,0.524980668,0.4572914583,0,0.4842825026],"purchase":[1,1,0,1,1],"device_type_Mobile":[0,1,1,0,0],"device_type_Tablet":[0,0,0,0,1],"device_type_Unknown":[0,0,0,1,0],"customer_type_Returning":[0,1,1,0,0]}},"total_rows":5,"truncation_type":null},"text/plain":"   customer_id  time_spent  ...  device_type_Unknown  customer_type_Returning\n0          501    0.664167  ...                  0.0                      0.0\n1          502    0.483681  ...                  0.0                      1.0\n2          503    0.231359  ...                  0.0                      1.0\n3          504    0.792944  ...                  1.0                      0.0\n4          505    0.649210  ...                  0.0                      0.0\n\n[5 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>time_spent</th>\n      <th>pages_viewed</th>\n      <th>basket_value</th>\n      <th>purchase</th>\n      <th>device_type_Mobile</th>\n      <th>device_type_Tablet</th>\n      <th>device_type_Unknown</th>\n      <th>customer_type_Returning</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>501</td>\n      <td>0.664167</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>502</td>\n      <td>0.483681</td>\n      <td>0.222222</td>\n      <td>0.524981</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>503</td>\n      <td>0.231359</td>\n      <td>0.111111</td>\n      <td>0.457291</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>504</td>\n      <td>0.792944</td>\n      <td>0.277778</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>505</td>\n      <td>0.649210</td>\n      <td>0.166667</td>\n      <td>0.484283</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":19}]},{"source":"# Task 3\n\nNow that all preparatory work has been done, create and train a neural network that would allow the company to predict purchases.\n\n- Using PyTorch, create a network with:\n   - At least one hidden layer with 8 units\n   - ReLU activation for hidden layer\n   - Sigmoid activation for the output layer\n- Using the prepared features in `input_model_features.csv`, train the model to predict purchases. \n- Use the validation dataset `validation_features.csv` to predict new values based on the trained model. \n- Your model should be named `purchase_model` and your output should be a DataFrame named `validation_predictions` with columns `customer_id` and `purchase`. The `purchase` column must be your predicted values.\n","metadata":{},"id":"10a02327-d528-441c-87bf-098f9d6415e1","cell_type":"markdown"},{"source":"# Task 3\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n\n# Load the prepared features and validation dataset\ninput_features = pd.read_csv('input_model_features.csv')\nvalidation_features = pd.read_csv('validation_features.csv')\n\n# Get feature columns (excluding 'purchase' and 'customer_id')\nfeature_cols = [col for col in input_features.columns \n               if col not in ['purchase', 'customer_id']]\n\n# Prepare features for both training and validation sets\nX_train = input_features[feature_cols].values\ny_train = input_features['purchase'].values\nX_val = validation_features[feature_cols].values\n\n# Convert to PyTorch tensors\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\nX_val = torch.tensor(X_val, dtype=torch.float32)\n\n# Define the neural network\nclass PurchaseModel(nn.Module):\n    def __init__(self, input_size):\n        super().__init__()\n        self.hidden = nn.Linear(input_size, 8)\n        self.output = nn.Linear(8, 1)\n        self.relu = nn.ReLU()\n        self.sigmoid = nn.Sigmoid()\n    \n    def forward(self, x):\n        x = self.relu(self.hidden(x))\n        x = self.sigmoid(self.output(x))\n        return x\n\n# Initialize the model\ninput_size = X_train.shape[1]\npurchase_model = PurchaseModel(input_size)\n\n# Define loss function and optimizer\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(purchase_model.parameters(), lr=0.01)\n\n# Train the model\nepochs = 100\nbatch_size = 32\nn_samples = len(X_train)\n\nfor epoch in range(epochs):\n    for i in range(0, n_samples, batch_size):\n        # Get batch\n        batch_X = X_train[i:i+batch_size]\n        batch_y = y_train[i:i+batch_size].reshape(-1, 1)\n        \n        optimizer.zero_grad()\n        outputs = purchase_model(batch_X)\n        loss = criterion(outputs, batch_y)\n        loss.backward()\n        optimizer.step()\n        \n    # Print progress every 10 epochs\n    if (epoch + 1) % 10 == 0:\n        with torch.no_grad():\n            train_predictions = purchase_model(X_train)\n            train_predictions = (train_predictions >= 0.5).float()\n            accuracy = (train_predictions.flatten() == torch.tensor(y_train)).float().mean()\n            print(f'Epoch [{epoch+1}/{epochs}], Training Accuracy: {accuracy:.4f}')\n\n# Make predictions on validation set\nwith torch.no_grad():\n    predictions = purchase_model(X_val)\n    predictions = (predictions >= 0.5).int()\n\n# Create output DataFrame\nvalidation_predictions = pd.DataFrame({\n    'customer_id': validation_features['customer_id'],\n    'purchase': predictions.numpy().flatten()\n})\n\n# Display first few predictions\nvalidation_predictions.head()","metadata":{"executionCancelledAt":null,"executionTime":5634,"lastExecutedAt":1740096483087,"lastExecutedByKernel":"32139c46-8d69-43b5-b167-7bde76e910ec","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Task 3\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n\n# Load the prepared features and validation dataset\ninput_features = pd.read_csv('input_model_features.csv')\nvalidation_features = pd.read_csv('validation_features.csv')\n\n# Get feature columns (excluding 'purchase' and 'customer_id')\nfeature_cols = [col for col in input_features.columns \n               if col not in ['purchase', 'customer_id']]\n\n# Prepare features for both training and validation sets\nX_train = input_features[feature_cols].values\ny_train = input_features['purchase'].values\nX_val = validation_features[feature_cols].values\n\n# Convert to PyTorch tensors\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\nX_val = torch.tensor(X_val, dtype=torch.float32)\n\n# Define the neural network\nclass PurchaseModel(nn.Module):\n    def __init__(self, input_size):\n        super().__init__()\n        self.hidden = nn.Linear(input_size, 8)\n        self.output = nn.Linear(8, 1)\n        self.relu = nn.ReLU()\n        self.sigmoid = nn.Sigmoid()\n    \n    def forward(self, x):\n        x = self.relu(self.hidden(x))\n        x = self.sigmoid(self.output(x))\n        return x\n\n# Initialize the model\ninput_size = X_train.shape[1]\npurchase_model = PurchaseModel(input_size)\n\n# Define loss function and optimizer\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(purchase_model.parameters(), lr=0.01)\n\n# Train the model\nepochs = 100\nbatch_size = 32\nn_samples = len(X_train)\n\nfor epoch in range(epochs):\n    for i in range(0, n_samples, batch_size):\n        # Get batch\n        batch_X = X_train[i:i+batch_size]\n        batch_y = y_train[i:i+batch_size].reshape(-1, 1)\n        \n        optimizer.zero_grad()\n        outputs = purchase_model(batch_X)\n        loss = criterion(outputs, batch_y)\n        loss.backward()\n        optimizer.step()\n        \n    # Print progress every 10 epochs\n    if (epoch + 1) % 10 == 0:\n        with torch.no_grad():\n            train_predictions = purchase_model(X_train)\n            train_predictions = (train_predictions >= 0.5).float()\n            accuracy = (train_predictions.flatten() == torch.tensor(y_train)).float().mean()\n            print(f'Epoch [{epoch+1}/{epochs}], Training Accuracy: {accuracy:.4f}')\n\n# Make predictions on validation set\nwith torch.no_grad():\n    predictions = purchase_model(X_val)\n    predictions = (predictions >= 0.5).int()\n\n# Create output DataFrame\nvalidation_predictions = pd.DataFrame({\n    'customer_id': validation_features['customer_id'],\n    'purchase': predictions.numpy().flatten()\n})\n\n# Display first few predictions\nvalidation_predictions.head()","outputsMetadata":{"0":{"height":185,"type":"stream"},"1":{"height":500,"type":"dataFrame","tableState":{"quickFilterText":""}}}},"id":"efcbda28-3c89-480d-b77a-c7f27ac759d5","cell_type":"code","execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch [10/100], Training Accuracy: 0.7900\nEpoch [20/100], Training Accuracy: 0.7864\nEpoch [30/100], Training Accuracy: 0.7806\nEpoch [40/100], Training Accuracy: 0.7791\nEpoch [50/100], Training Accuracy: 0.7784\nEpoch [60/100], Training Accuracy: 0.7791\nEpoch [70/100], Training Accuracy: 0.7791\nEpoch [80/100], Training Accuracy: 0.7784\nEpoch [90/100], Training Accuracy: 0.7784\nEpoch [100/100], Training Accuracy: 0.7762\n"},{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"customer_id","type":"integer"},{"name":"purchase","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"customer_id":[1801,1802,1803,1804,1805],"purchase":[1,1,1,0,1]}},"total_rows":5,"truncation_type":null},"text/plain":"   customer_id  purchase\n0         1801         1\n1         1802         1\n2         1803         1\n3         1804         0\n4         1805         1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>purchase</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1801</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1802</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1803</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1804</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1805</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":30}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"editor":"DataLab","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":5}